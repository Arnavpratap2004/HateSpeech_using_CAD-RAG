{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c72a5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Block 1: Installation\n",
    "!pip install langchain langchain-openai langchain-community neo4j psycopg2-binary pgvector spacy chromadb newsapi-python python-dotenv pandas langchain_google_genai openpyxl\n",
    "!pip install 'langchain-community[docloaders]'\n",
    "!python -m spacy download en_core_web_lg\n",
    "\n",
    "# Block 2: Setup API Keys and Google Drive\n",
    "import os\n",
    "from google.colab import userdata, drive\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Mount Google Drive to save our data\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load API keys from Colab secrets\n",
    "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
    "os.environ['NEWS_API_KEY'] = userdata.get('NEWS_API_KEY')\n",
    "os.environ['NEO4J_URI'] = userdata.get('NEO4J_URI')\n",
    "os.environ['NEO4J_USERNAME'] = userdata.get('NEO4J_USERNAME')\n",
    "os.environ['NEO4J_PASSWORD'] = userdata.get('NEO4J_PASSWORD')\n",
    "\n",
    "print(\"Environment setup complete. API keys and Google Drive are configured.\")\n",
    "\n",
    "# Block 3: Initialize ChromaDB Vector Store\n",
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Define the path in your Google Drive for persistence\n",
    "CHROMA_PATH = \"/content/drive/MyDrive/cad_rag_chroma\"\n",
    "\n",
    "# Initialize the embedding function\n",
    "embedding_function = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Initialize the ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "# Create or get the collections for our lexicons\n",
    "slur_lexicon_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"slur_lexicon\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "reclaimed_speech_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"reclaimed_speech\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# Create LangChain vector store objects\n",
    "slur_lexicon_db = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=\"slur_lexicon\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "\n",
    "reclaimed_speech_db = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=\"reclaimed_speech\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "\n",
    "print(f\"ChromaDB initialized at: {CHROMA_PATH}\")\n",
    "print(f\"Number of items in slur lexicon: {slur_lexicon_db._collection.count()}\")\n",
    "print(f\"Number of items in reclaimed speech corpus: {reclaimed_speech_db._collection.count()}\")\n",
    "\n",
    "# Block 4: Populate Knowledge Base with Initial Data\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import spacy\n",
    "from newsapi import NewsApiClient\n",
    "import os\n",
    "\n",
    "# --- 1. Populate Slur Lexicon and Reclaimed Speech Corpus ---\n",
    "# Manually create some initial data\n",
    "slur_data = {\n",
    "    'term': ['gloober', 'zorp'],\n",
    "    'definition': [\n",
    "        'A derogatory term for immigrants from a specific region, popularized by online hate groups.',\n",
    "        'A coded term used to insult a political group.'\n",
    "    ],\n",
    "    'target_group': ['Immigrants', 'Political Opponents']\n",
    "}\n",
    "slur_df = pd.DataFrame(slur_data)\n",
    "\n",
    "reclaimed_data = {\n",
    "    'text':['', ''],\n",
    "    'source': ['Community Forum A', 'Academic Paper on Linguistics']\n",
    "}\n",
    "reclaimed_df = pd.DataFrame(reclaimed_data)\n",
    "\n",
    "# Add to ChromaDB (if not already present)\n",
    "if slur_lexicon_db._collection.count() == 0:\n",
    "    slur_lexicon_db.add_texts(\n",
    "        texts=slur_df['definition'].tolist(),\n",
    "        metadatas=[{'term': row['term'], 'target': row['target_group']} for _, row in slur_df.iterrows()],\n",
    "        ids=[f\"slur_{i}\" for i in range(len(slur_df))]\n",
    "    )\n",
    "    print(\"Added initial data to slur lexicon.\")\n",
    "\n",
    "if reclaimed_speech_db._collection.count() == 0:\n",
    "    reclaimed_speech_db.add_texts(\n",
    "        texts=reclaimed_df['text'].tolist(),\n",
    "        metadatas=[{'source': row['source']} for _, row in reclaimed_df.iterrows()],\n",
    "        ids=[f\"reclaimed_{i}\" for i in range(len(reclaimed_df))]\n",
    "    )\n",
    "    print(\"Added initial data to reclaimed speech corpus.\")\n",
    "\n",
    "\n",
    "# --- 2. Simulate Real-Time News Ingestion for Knowledge Graph ---\n",
    "# Initialize clients\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "newsapi = NewsApiClient(api_key=os.environ.get('NEWS_API_KEY'))\n",
    "neo4j_driver = GraphDatabase.driver(os.environ.get('NEO4J_URI'), auth=(os.environ.get('NEO4J_USERNAME'), os.environ.get('NEO4J_PASSWORD')))\n",
    "\n",
    "def ingest_article_to_kg(tx, article):\n",
    "    \"\"\"A function to ingest a single news article into the Neo4j Knowledge Graph.\"\"\"\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (e:Event {url: $url})\n",
    "        ON CREATE SET e.title = $title, e.summary = $summary, e.date = datetime($date)\n",
    "        \"\"\",\n",
    "        url=article['url'],\n",
    "        title=article['title'],\n",
    "        summary=article['description'] or \"No description available.\",\n",
    "        date=article['publishedAt']\n",
    "    )\n",
    "    doc = nlp(article['title'])\n",
    "    relevant_entity_types = ['PERSON', 'ORG', 'GPE', 'NORP']\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in relevant_entity_types:\n",
    "            tx.run(\"\"\"\n",
    "                MERGE (e:Event {url: $url})\n",
    "                MERGE (en:Entity {name: $name})\n",
    "                ON CREATE SET en.type = $type\n",
    "                MERGE (e)-->(en)\n",
    "                \"\"\",\n",
    "                url=article['url'], name=ent.text, type=ent.label_\n",
    "            )\n",
    "\n",
    "print(\"\\nFetching and ingesting recent news articles into Knowledge Graph...\")\n",
    "try:\n",
    "    all_articles = newsapi.get_everything(q='immigration policy', language='en', sort_by='publishedAt', page_size=10)\n",
    "    with neo4j_driver.session() as session:\n",
    "        for article in all_articles['articles']:\n",
    "            session.execute_write(ingest_article_to_kg, article)\n",
    "    print(f\"Successfully ingested {len(all_articles['articles'])} articles into Neo4j.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not fetch news articles. Error: {e}. This may be due to API rate limits or incorrect Neo4j credentials.\")\n",
    "\n",
    "# Block 5: Pre-Retrieval Analysis Function\n",
    "def pre_retrieval_analysis(text: str):\n",
    "    \"\"\"Extracts named entities and potential neologisms from text.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    neologisms = [token.text for token in doc if token.is_oov]\n",
    "    return {\"entities\": list(set(entities)), \"neologisms\": list(set(neologisms))}\n",
    "\n",
    "# Block 6: RAG Core - Multi-Query Agent\n",
    "from langchain.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def lexical_query(term: str) -> str:\n",
    "    \"\"\"Searches the Evolving Slur Lexicon for a definition and origin of a given term.\"\"\"\n",
    "    print(f\"--- EXECUTING LEXICAL QUERY for '{term}' ---\")\n",
    "    docs = slur_lexicon_db.similarity_search(term, k=1)\n",
    "    if docs:\n",
    "        return f\"Lexicon Result for '{term}': {docs[0].page_content} (Target: {docs[0].metadata.get('target', 'N/A')})\"\n",
    "    return f\"Lexicon Result for '{term}': Term not found.\"\n",
    "\n",
    "# neo4j_driver is already initialized in Block 4\n",
    "@tool\n",
    "def contextual_query(entity: str) -> str:\n",
    "    \"\"\"Searches the Knowledge Graph for recent news or controversies related to a specific entity.\"\"\"\n",
    "    print(f\"--- EXECUTING CONTEXTUAL QUERY for '{entity}' ---\")\n",
    "    with neo4j_driver.session() as session:\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (e:Event)-->(en:Entity)\n",
    "            WHERE toLower(en.name) CONTAINS toLower($entity)\n",
    "            RETURN e.title, e.summary\n",
    "            ORDER BY e.date DESC\n",
    "            LIMIT 2\n",
    "            \"\"\", entity=entity)\n",
    "        events = [f\"{record['e.title']}: {record['e.summary']}\" for record in result]\n",
    "    if events:\n",
    "        return f\"Contextual Result for '{entity}': Recently mentioned in news: \" + \" | \".join(events)\n",
    "    return f\"Contextual Result for '{entity}': No recent news events found in the knowledge graph.\"\n",
    "\n",
    "@tool\n",
    "def counter_evidence_query(term: str) -> str:\n",
    "    \"\"\"Searches the Corpus of Reclaimed Speech for non-hateful uses of a given term.\"\"\"\n",
    "    print(f\"--- EXECUTING COUNTER-EVIDENCE QUERY for '{term}' ---\")\n",
    "    docs = reclaimed_speech_db.similarity_search(term, k=1)\n",
    "    if docs:\n",
    "        return f\"Counter-Evidence Result for '{term}': Found a potential non-hateful usage: '{docs[0].page_content}'\"\n",
    "    return f\"Counter-Evidence Result for '{term}': No instances found in reclaimed speech corpora.\"\n",
    "\n",
    "tools = [lexical_query, contextual_query, counter_evidence_query]\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", google_api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "agent_prompt_template = \"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Input: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "agent_prompt = PromptTemplate.from_template(agent_prompt_template)\n",
    "\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# --- Start of new model integration and refined functions ---\n",
    "\n",
    "# Import necessary libraries for model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss, jaccard_score, classification_report\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Load and Train Original Model (jigsaw-toxic-comment-classification-challenge) ---\n",
    "# Define the path to the train.csv file\n",
    "train_file_path_original = '/tmp/train.csv'\n",
    "test_file_path_original = '/tmp/traintest.csv' # Path to the test data\n",
    "\n",
    "# Define the label columns used during training\n",
    "label_columns = ['hate_speech', 'offensive_language', 'neither']\n",
    "\n",
    "\n",
    "# Check if train.csv exists.\n",
    "if os.path.exists(train_file_path_original):\n",
    "    try:\n",
    "        # Load the train.csv file into a pandas DataFrame\n",
    "        df_train = pd.read_csv(train_file_path_original)\n",
    "        print(\"\\ntrain.csv loaded successfully for original model training.\")\n",
    "\n",
    "        # **MERGED CODE**: Binarize the label columns.\n",
    "        print(\"\\nBinarizing label columns for training data...\")\n",
    "        for label in label_columns:\n",
    "            df_train[label] = (df_train[label] > 0).astype(int)\n",
    "        print(\"Binarization complete.\")\n",
    "\n",
    "        # --- Analyze Class Distribution (Train) ---\n",
    "        print(\"\\nClass distribution in training data (after binarization):\")\n",
    "        print(df_train[label_columns].sum())\n",
    "\n",
    "        # --- Remove rows with NaN labels ---\n",
    "        initial_rows = len(df_train)\n",
    "        df_train.dropna(subset=label_columns, inplace=True)\n",
    "        rows_removed = initial_rows - len(df_train)\n",
    "        print(f\"Removed {rows_removed} rows with NaN labels from train.csv.\")\n",
    "\n",
    "\n",
    "        # Perform basic text cleaning for original model\n",
    "        print(\"\\nStarting text cleaning and preprocessing steps for original model training...\")\n",
    "        df_train['tweet'] = df_train['tweet'].fillna('')\n",
    "        df_train['tweet'] = df_train['tweet'].str.lower()\n",
    "        df_train['tweet'] = df_train['tweet'].apply(lambda x: re.sub(r'[^a-z0-9\\s]', '', x))\n",
    "        df_train['tweet'] = df_train['tweet'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "        print(\"Text cleaning and preprocessing steps completed for original model training.\")\n",
    "\n",
    "        # Define the features (text) and labels for original model\n",
    "        X_original = df_train['tweet']\n",
    "        y_original = df_train[label_columns]\n",
    "\n",
    "        # MODIFICATION: Increased max_features to 10000\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "        # Fit the vectorizer and transform data for original model\n",
    "        X_train_tfidf = tfidf_vectorizer.fit_transform(X_original)\n",
    "\n",
    "        # Initialize and train the original LogisticRegression model with class_weight='balanced'\n",
    "        logistic_regression_model = MultiOutputClassifier(LogisticRegression(solver='sag', class_weight='balanced', random_state=42))\n",
    "        print(\"\\nOriginal Logistic Regression model initialized with class_weight='balanced'.\")\n",
    "\n",
    "        print(\"\\nTraining the original Logistic Regression model...\")\n",
    "        logistic_regression_model.fit(X_train_tfidf, y_original)\n",
    "        print(\"Original model training completed.\")\n",
    "\n",
    "        # --- Evaluate Original Model ---\n",
    "        if os.path.exists(test_file_path_original):\n",
    "            try:\n",
    "                df_test = pd.read_csv(test_file_path_original) # Read as CSV\n",
    "                print(f\"\\n'{test_file_path_original}' loaded successfully for original model evaluation.\")\n",
    "\n",
    "                # **MERGED CODE**: Binarize the label columns for the test data as well.\n",
    "                print(\"\\nBinarizing label columns for test data...\")\n",
    "                for label in label_columns:\n",
    "                    df_test[label] = (df_test[label] > 0).astype(int)\n",
    "                print(\"Binarization complete.\")\n",
    "\n",
    "                # --- Analyze Class Distribution (Test) ---\n",
    "                print(\"\\nClass distribution in test data (after binarization):\")\n",
    "                print(df_test[label_columns].sum())\n",
    "\n",
    "                # Assuming the test set has the same structure and label columns as the training set\n",
    "                # Convert 'comment_text' to string type to handle potential non-string data\n",
    "                df_test['tweet'] = df_test['tweet'].astype(str).fillna('')\n",
    "                X_test_original = df_test['tweet']\n",
    "                X_test_original = X_test_original.str.lower()\n",
    "                X_test_original = X_test_original.apply(lambda x: re.sub(r'[^a-z0-9\\s]', '', x))\n",
    "                X_test_original = X_test_original.apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "                y_test_original = df_test[label_columns].dropna()\n",
    "                X_test_original = X_test_original[y_test_original.index]\n",
    "\n",
    "\n",
    "                # Transform the test data using the fitted vectorizer\n",
    "                X_test_tfidf = tfidf_vectorizer.transform(X_test_original)\n",
    "\n",
    "                # Make predictions on the test data using predict_proba\n",
    "                y_pred_proba_original = logistic_regression_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "                # Apply a custom threshold to get final predictions\n",
    "                # Note: predict_proba returns a list of arrays, one for each label.\n",
    "                # We stack them and then apply the threshold.\n",
    "                probs_positive_class = np.array([p[:, 1] for p in y_pred_proba_original]).T\n",
    "\n",
    "                # MODIFICATION: Increased threshold to 0.8 for higher precision\n",
    "                custom_threshold = 0.8\n",
    "                y_pred_original = (probs_positive_class >= custom_threshold).astype(int)\n",
    "                print(f\"\\nUsing custom prediction threshold for high precision: {custom_threshold}\")\n",
    "\n",
    "\n",
    "                # Calculate evaluation metrics\n",
    "                print(\"\\nOriginal Model Evaluation Metrics:\")\n",
    "                for i, label in enumerate(label_columns):\n",
    "                    print(f\"\\nMetrics for label: {label}\")\n",
    "                    print(f\"  Accuracy: {accuracy_score(y_test_original.iloc[:, i], y_pred_original[:, i]):.4f}\")\n",
    "                    print(f\"  Precision: {precision_score(y_test_original.iloc[:, i], y_pred_original[:, i], zero_division=0):.4f}\")\n",
    "                    print(f\"  Recall: {recall_score(y_test_original.iloc[:, i], y_pred_original[:, i], zero_division=0):.4f}\")\n",
    "                    print(f\"  F1 Score: {f1_score(y_test_original.iloc[:, i], y_pred_original[:, i], zero_division=0):.4f}\")\n",
    "\n",
    "                # Calculate overall metrics\n",
    "                print(\"\\nOverall Original Model Metrics:\")\n",
    "                print(f\"  Hamming Loss: {hamming_loss(y_test_original, y_pred_original):.4f}\")\n",
    "                print(f\"  Jaccard Score (samples): {jaccard_score(y_test_original, y_pred_original, average='samples'):.4f}\")\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during original model evaluation: {e}\")\n",
    "        else:\n",
    "            print(f\"\\nError: '{test_file_path_original}' not found for original model evaluation. Please ensure the dataset is in the /tmp/ directory.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the original model training process: {e}\")\n",
    "else:\n",
    "    print(f\"\\nError: {train_file_path_original} not found for original model training. Please ensure the dataset is in the /tmp/ directory.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Refined Sentence Type Analysis and Dynamic Prompting ---\n",
    "\n",
    "def create_dynamic_prompt(original_sentence, context_from_rag, expert_type=\"General Hate\"):\n",
    "    \"\"\"Creates the final, context-rich prompt for the expert LLM.\"\"\"\n",
    "    PROMPT_TEMPLATE = \"\"\"You are an expert at detecting {hate_type} hate speech. Your task is to analyze the following sentence based on the provided real-time context and generate a classification (HATEFUL/NOT_HATEFUL) with a detailed rationale.\n",
    "\n",
    "Sentence: '{sentence}'\n",
    "\n",
    "Retrieved Context:\n",
    "{context_block}\n",
    "\n",
    "Analysis Task: Based ONLY on the sentence and the provided context, classify the sentence and explain your reasoning.\n",
    "\"\"\"\n",
    "    return PROMPT_TEMPLATE.format(\n",
    "        hate_type=expert_type,\n",
    "        sentence=original_sentence,\n",
    "        context_block=context_from_rag['output'] if isinstance(context_from_rag, dict) and 'output' in context_from_rag else context_from_rag\n",
    "    )\n",
    "\n",
    "def determine_sentence_type(sentence: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyses a sentence to determine its potential hate speech category based on keywords, entities, and patterns.\n",
    "\n",
    "    Args:\n",
    "        sentence: The input sentence.\n",
    "\n",
    "    Returns:\n",
    "        A string indicating the most likely hate speech category.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence.lower())\n",
    "\n",
    "    religion_indicators = [\"muslims are\", \"islamic extremists\", \"hindu nationalists\", \"christian fundamentalists\", \"jewish conspiracy\", \"sikh separatists\", \"buddhist persecution\", \"anti-muslim\", \"anti-christian\", \"anti-jewish\", \"anti-sikh\", \"anti-buddhist\", \"religious fanatic\", \"infidels\", \"blasphemy\", \"jihad\", \"crusade\", \"sharia\", \"temple demolition\", \"mosque attack\", \"church bombing\", \"synagogue vandalism\", \"religious fanatics\", \"people of faith are\"]\n",
    "    political_indicators = [\"opposition are traitors\", \"government is corrupt\", \"political elite is\", \"leftist agenda is\", \"right-wing extremist are\", \"political enemies are\", \"election fraud is\", \"deep state is\", \"political propaganda is\", \"political violence is\", \"political purges are\", \"congress party is thug\"]\n",
    "    gender_indicators = [\"women belong in the kitchen\", \"men are superior to\", \"feminazis are\", \"male fragility is\", \"gender fluid is not real\", \"transgenders are not\", \"sexual predators are\", \"misogynistic comments\", \"patriarchal oppression is\", \"sexist remarks are\", \"women are too emotional\"]\n",
    "    caste_indicators = [\"lower castes are inferior\", \"upper castes are\", \"dalit oppression is\", \"brahminical supremacy is\", \"caste hierarchy is\", \"caste-based violence is\"]\n",
    "    cyberbullying_indicators = [\"going to dox that person\", \"expose on social media\", \"online harassment campaign\", \"troll army is\", \"cyberstalking is\", \"sending threats online\", \"online abuse is\", \"internet mob is\", \"comment warriors are\"]\n",
    "    subtle_hate_indicators = [\"you know the type of people\", \"those kind of people always\", \"some groups just always\", \"they're all the same\", \"it's just a joke relax\", \"can't you take a joke\", \"playing the victim card again\", \"coded language used\", \"dog whistle politics\", \"sarcastic remark about\"]\n",
    "\n",
    "    if any(phrase in doc.text for phrase in caste_indicators):\n",
    "        return \"Caste-based hate\"\n",
    "    if any(phrase in doc.text for phrase in religion_indicators):\n",
    "        return \"Religion-based hate\"\n",
    "    if any(phrase in doc.text for phrase in gender_indicators):\n",
    "        return \"Gender-based hate\"\n",
    "    if any(phrase in doc.text for phrase in political_indicators):\n",
    "        return \"Political hate\"\n",
    "    if any(phrase in doc.text for phrase in cyberbullying_indicators):\n",
    "        return \"Cyberbullying & personal attacks\"\n",
    "    if any(phrase in doc.text for phrase in subtle_hate_indicators):\n",
    "        return \"Subtle hate (sarcasm, euphemism, coded language)\"\n",
    "\n",
    "    religion_keywords = [\"muslim\", \"islam\", \"hindu\", \"christian\", \"jew\", \"sikh\", \"buddhist\", \"religion\", \"religious\", \"faith\", \"allah\", \"jesus\", \"temple\", \"mosque\", \"church\"]\n",
    "    political_keywords = [\"political\", \"government\", \"party\", \"vote\", \"election\", \"politician\", \"liberal\", \"conservative\", \"democrat\", \"republican\", \"traitor\", \"propaganda\", \"regime\", \"congress\"]\n",
    "    gender_keywords = [\"man\", \"woman\", \"male\", \"female\", \"guy\", \"girl\", \"boy\", \"she\", \"he\", \"her\", \"him\", \"gender\", \"feminist\", \"sexist\", \"women\", \"men\", \"girls\", \"boys\"]\n",
    "    caste_keywords = [\"caste\", \"dalit\", \"brahmin\", \"shudra\", \"kshatriya\", \"varna\", \"jati\", \"chamar\"]\n",
    "    cyberbullying_keywords = [\"online\", \"internet\", \"social media\", \"forum\", \"comment\", \"twitter\", \"facebook\", \"instagram\", \"tiktok\", \"snapchat\", \"dox\", \"troll\", \"cyber\"]\n",
    "    subtle_hate_keywords = [\"subtle\", \"implicit\", \"coded\", \"sarcasm\", \"euphemism\", \"innuendo\", \"different\", \"type\", \"sort\"]\n",
    "\n",
    "    if any(keyword in doc.text for keyword in caste_keywords):\n",
    "        return \"Caste-based hate\"\n",
    "    if any(keyword in doc.text for keyword in religion_keywords):\n",
    "        return \"Religion-based hate\"\n",
    "    if any(keyword in doc.text for keyword in gender_keywords):\n",
    "        return \"Gender-based hate\"\n",
    "    if any(keyword in doc.text for keyword in political_keywords):\n",
    "        return \"Political hate\"\n",
    "    if any(keyword in doc.text for keyword in cyberbullying_keywords):\n",
    "        return \"Cyberbullying & personal attacks\"\n",
    "    if any(keyword in doc.text for keyword in subtle_hate_keywords):\n",
    "        return \"Subtle hate (sarcasm, euphemism, coded language)\"\n",
    "\n",
    "    if not any(indicator in doc.text for indicators_list in [religion_indicators, political_indicators, gender_indicators, caste_indicators, cyberbullying_indicators, subtle_hate_indicators] for indicator in indicators_list) and \\\n",
    "       not any(keyword in doc.text for keywords_list in [religion_keywords, political_keywords, gender_keywords, caste_keywords, cyberbullying_keywords, subtle_hate_keywords] for keyword in keywords_list):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in ['PERSON', 'ORG', 'GPE', 'NORP']:\n",
    "                return \"Political hate\"\n",
    "\n",
    "    return \"General Hate\"\n",
    "\n",
    "# --- Combined Classification Function ---\n",
    "def classify_hate_speech_combined(sentence: str) -> dict:\n",
    "    \"\"\"\n",
    "    Classifies a sentence using the trained model.\n",
    "\n",
    "    Args:\n",
    "        sentence: The input sentence to classify.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing model classifications.\n",
    "    \"\"\"\n",
    "    classifications = {}\n",
    "\n",
    "    if 'tfidf_vectorizer' in globals() and 'logistic_regression_model' in globals():\n",
    "        try:\n",
    "            cleaned_sentence = sentence.lower()\n",
    "            cleaned_sentence = re.sub(r'[^a-z0-9\\s]', '', cleaned_sentence)\n",
    "            cleaned_sentence = re.sub(r'\\s+', ' ', cleaned_sentence).strip()\n",
    "            sentence_tfidf = tfidf_vectorizer.transform([cleaned_sentence])\n",
    "\n",
    "            # Predict probabilities and apply the high-precision threshold\n",
    "            pred_probs = logistic_regression_model.predict_proba(sentence_tfidf)\n",
    "            probs_positive_class = np.array([p[:, 1] for p in pred_probs]).T[0]\n",
    "\n",
    "            # Use the same high threshold as in evaluation\n",
    "            custom_threshold = 0.8\n",
    "            predictions = (probs_positive_class >= custom_threshold).astype(int)\n",
    "\n",
    "            is_hateful_original = any(predictions)\n",
    "            classifications['original_model'] = \"HATEFUL\" if is_hateful_original else \"NOT_HATEFUL\"\n",
    "            predicted_labels = [label_columns[i] for i, pred in enumerate(predictions) if pred == 1]\n",
    "            classifications['original_model_labels'] = predicted_labels\n",
    "\n",
    "        except Exception as e:\n",
    "            classifications['original_model'] = f\"Error: {e}\"\n",
    "    else:\n",
    "        classifications['original_model'] = \"Model not available.\"\n",
    "\n",
    "\n",
    "    return classifications\n",
    "\n",
    "# --- Main Analysis Function (analyze_sentence) ---\n",
    "def analyze_sentence(sentence: str):\n",
    "    \"\"\"\n",
    "    Analyses a sentence for potential hate speech using the defined RAG model\n",
    "    and the trained classification models.\n",
    "\n",
    "    Args:\n",
    "        sentence: The input sentence to analyze.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing model classifications and the LLM rationale.\n",
    "    \"\"\"\n",
    "    print(f\"--- Analyzing Sentence: '{sentence}' ---\")\n",
    "\n",
    "    # 1. Pre-Retrieval Analysis\n",
    "    analysis_result = pre_retrieval_analysis(sentence)\n",
    "    print(f\"Analysis Result: {analysis_result}\")\n",
    "\n",
    "    # 2. Determine Sentence Type for Expert Routing (for RAG)\n",
    "    expert_type = determine_sentence_type(sentence)\n",
    "    print(f\"Determined Expert Type (for RAG): {expert_type}\")\n",
    "\n",
    "    # 3. Trained Model Classifications\n",
    "    model_classifications = classify_hate_speech_combined(sentence)\n",
    "    print(f\"\\nTrained Model Classifications: {model_classifications}\")\n",
    "\n",
    "    # 4. RAG Core - Multi-Query Agent\n",
    "    analysis_input_str = f\"Analyzed text contains entities: {analysis_result.get('entities', [])} and neologisms: {analysis_result.get('neologisms', [])}\"\n",
    "    print(f\"Agent Input: {analysis_input_str}\")\n",
    "    retrieved_context = {\"output\": \"Agent execution failed.\"} # Initialize retrieved_context\n",
    "    try:\n",
    "        retrieved_context = agent_executor.invoke({\"input\": analysis_input_str})\n",
    "        print(f\"\\nRetrieved Context: {retrieved_context['output']}\")\n",
    "    except NameError:\n",
    "        print(\"Error: agent_executor is not defined. Please ensure Block 6 has been executed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Agent execution: {e}\")\n",
    "\n",
    "\n",
    "    # 5. Dynamic Prompting and Final Decision (LLM Rationale)\n",
    "    final_prompt_for_expert = create_dynamic_prompt(\n",
    "        original_sentence=sentence,\n",
    "        context_from_rag=retrieved_context,\n",
    "        expert_type=expert_type\n",
    "    )\n",
    "    print(\"\\n--- DYNAMIC PROMPT FOR EXPERT (for Rationale) ---\")\n",
    "    print(final_prompt_for_expert)\n",
    "\n",
    "    try:\n",
    "        expert_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", google_api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "        final_decision_llm = expert_llm.invoke(final_prompt_for_expert)\n",
    "        llm_rationale = final_decision_llm.content\n",
    "        print(\"\\n--- LLM RATIONALE ---\")\n",
    "        print(llm_rationale)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during LLM rationale generation: {e}\")\n",
    "        llm_rationale = f\"LLM rationale generation failed: {e}\"\n",
    "\n",
    "    return {\"model_classifications\": model_classifications, \"llm_rationale\": llm_rationale}\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "test_sentence = \"All muslims should be kicked out\"\n",
    "analysis_output = analyze_sentence(test_sentence)\n",
    "print(\"\\n--- Final Analysis Output (Model + LLM) ---\")\n",
    "print(analysis_output)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
